# 【并发】



# 【MySQL】

## 什么是索引

数据库维护了特定的数据结构，以满足特定的查找算法，从而快速定位数据，这种存储结构就是索引，其设计思想基于空间换时间

## 索引分类

- 数据结构分类：B+树、Hash索引、Full-Text索引
- 物理存储分类：聚簇索引（主键索引）、二级索引（辅助索引）
  - 聚簇索引：索引值和数据存在一块，主键索引即聚簇索引
  - 二级索引：索引值和主键放一起，可能需要回表
- 字段特性分类：主键索引、唯一索引、常规索引、全文索引
- 字段个数分类：单列索引、联合索引

## 索引的优缺点

**优点：**

- 提高数据检索效率，降低数据库IO成本
- 唯一索引保证数据唯一性
- 使用分组、排序子句进行数据检索时，可以显著减少查询中分组和排序的时间
- 加速两个表的连接，一般是在外键上创建索引

**缺点：**

- 占用物理空间，索引越多空间越大
- 创建和维护索引需要耗费时间，会降低表的增删改效率

## 创建索引的方式

- CREATE语句创建表时指明

  ```mysql
  CREATE TABLE user {
  	id INT AUTO_INCREMENT PRIMARY KEY
  };
  
  CREATE TABLE user {
  	id INT,
  	INDEX index_id(id)
  };
  ```

- `ALTER TABLE` 

  ```mysql
  ALTER TABLE user ADD INDEX name_index(name);
  ```

- `CREATE INDEX`

  ```mysql
  CREATE INDEX name_index ON user(name);
  ```

## B+树索引

默认存储引擎 InnoDB 使用b+树索引

- **B+树的磁盘读写次数少，且代价更低：**

  B+树是一棵平衡的多路查找树，其高度较低（相较于二叉查找树），且因为仅在叶子结点存放索引值所以内存占用少（相较于b树），所以一次可以加载更多的节点，磁盘寻址加载次数少

- **B+树范围查找优势：**

  B+树的叶子结点之间是一个有序的双向链表（相较于hash结构），可以很好的支持范围查找、模糊匹配，不需要跨层访问

**相较于其他数据结构：**

- `链表`：B+树维护了树形结构，满足特定查找算法，效率更高
- `hash表`：等值查询方面hash表更有优势，但B+树底层叶子结点构成有序双向循环链表，在范围查询方面效率更高
- `B树`：仅在叶子结点存储索引值和主键（聚簇索引存数据），并将叶子结点串成双向循环链表；磁盘IO代价更小，固定时间复杂度为（logn）且大大增加区间访问性，范围查询效率更快
- `红黑树`：B+树是多路查找树，高度更低，磁盘IO次数更少

**B+树分裂：**

当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针

## 存储引擎比较

![在这里插入图片描述](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master1fb61b5d074f4312ae90196b97f5b049.png)

## 一条sql执行的很慢的原因

**偶尔很慢：**

- **数据库同步数据到磁盘（刷新脏页）：**

  数据库会在内存中更新数据并写入redolog日志，在空闲时同步到磁盘；如果redolog写满了会暂停其他工作去同步磁盘，可能导致SQL执行慢了

- **拿不到锁：**

  可能当前执行的SQL语句涉及的表被别人加锁了，需要等别人释放锁才能拿到锁

  `show processlist`:显示用户正在运行的线程，可以从command和status字段查看当前线程正处于的状态，判断是否在等待锁

- **SQL写得太烂了：**比如在在循环语句里写sql

**针对一直很慢的情况：**

- 没建立索引或者索引失效，走全表扫描

  - 不满足最左前缀原则
  - 使用运算或函数

- 有索引，但执行全表扫描

  系统根据**索引的区分度**（`count(distinct 具体的列) / count(*)`）来判断是否要走索引，区分度越高说明索引上不同的值越多，走索引查询越有优势

  但是系统是通过采样的方式来预测索引的区分度的，可能会因为统计的失误导致走了全表扫描

  ```mysql
  -- 强制使用索引
  select * from t force index(a) where c < 100 and c < 100000;
  -- 查询基数与实际是否符合
  show index from t;
  -- 重新统计索引基数
  analyze table t;
  ```

## ？慢SQL优化

**1.配置慢查询**

```mysql
SET GLOBAL slow_query_log='ON';
SET GLOBAL long_query_time=2;
```

```properties
long_query_time=2
slow-query-log=On
```

**2.分析慢查询日志，定位执行效率比较低的SQL**

**3.通过explain关键字分析SQL的执行计划**

关注的字段：

- **type：**
  - type=ALL，全表扫描，MySQL遍历全表来找到匹配行
  - type=index，索引全扫描
  - type=range，索引范围扫描
  - type=eq_ref，唯一索引
  - type=NULL，MySQL不用访问表或者索引，直接就能够得到结果（性能最好）
- **possible_keys：** 可能用到的索引
- **key：** 实际用到的索引
- **key_length:** 实际使用的索引字段的长度
- **rows：**扫描的行数
- **extra：**
  - using index：覆盖索引，不回表
  - using where：回表查询
  - using filesort：需要额外的排序，不能通过索引得到排序结果

**4.优化**

- **索引优化：**

  - 尽量覆盖索引，5.6支持索引下推

  - 组合索引符合最左匹配原则，同时要避免索引失效

  - 再写多读少的场景下，可以选择普通索引而不要唯一索引

    因为执行更新语句时，如果数据页没有在内存中，会将更新操作缓存到 change buffer 中，之后再进行 merge,真正进行数据更新，减少磁盘IO，提高性能

    而change buffer主要用于**二级非唯一索引数据**的新增、修改或删除操作，不适用于主键索引、空间索引、全文索引和唯一索引，所以写多读少可以用普通索引

  - 索引建立原则（一般建在where和order by，基数要大，区分度要高，不要过度索引，外键建索引）

- **SQL优化**

  - 分页查询优化：主键自增的表，limit查询可以通过限定主键范围来确定页号
  - insert优化：
    - 多条插入语句写成一条
    - 在事务中插数据
    - 数据有序插入


## 事务/四大特性

**事务：** 事务把所有的命令作为一个整体一起向系统提交或撤销操作请求，即这一组数据库命令要么同时成功，要么同时失败

**四大特性：**

- **A：Atomic 原子性** 事务是不可分割的最小操作单元，要么全部执行，要么全部不执行；
- **C：Consistent 一致性** 事务完成后，所有数据的状态都是一致的，即A账户只要减去了100，B账户则必定加上了100；
- **I：Isolation 隔离性** 如果有多个事务并发执行，同时操作一批数据，每个事务作出的修改必须与其他事务隔离，隔离性越强，即看不见别的事务对数据的修改，同时性能越低；
- **D：Duration 持久性** 即事务完成后，对数据库数据的修改被持久化存储。

## MVCC实现原理

多版本并发控制（MVCC）可以解决读-写并发冲突，提高并发性能。

简单来说，MVCC就是存储了同一条数据的不同历史版本链，不同事物可以访问不同的数据版本（版本快照）（适合读已提交和可重复读）

**当前读和快照读：**

- **当前读：**就是读取记录的当前最新版本，其他事物不能修改记录(增删改查和`select...for update/ lock in share mode`，即加锁)
- **快照读：** 读取MVCC版本链中的某个快照版本，不需要加锁

### 隐藏字段

- `DB_TRX_ID`：创建或者修改的数据的事务ID
- `DB_ROLL_PTR`：回滚指针，指向记录的上一个版本（在undo log中）

多版本数据链使用UNDO（回滚）日志实现，回滚日志存储了修改值的记录的原值（旧版本）

### 版本链

在修改数据的时候，

MySQL除了执行redo log（物理日志）和bin log（逻辑日志）的两阶段提交，还会记录一个undo log，用于事务回滚；

MVCC的版本链就是在undo log上形成的；

### 版本快照

**Read View 读视图**

读视图是事务进行快照读产生的读视图，记录并维护系统当前活跃事务的id数组（事务先后顺序通过事务id大小判断）

- **读已提交：**ReadView会在事务中的每一个SELECT语句查询发送前生成
- **可重复读：**ReadView会在事务的第一个SELECT语句查询发送前生成，且之后的SELECT都是基于这个ReadView

### 快照生成

某个事务进行快照读时可以读到哪个版本的数据，ReadView有一套算法：

**当查询发生时生成ReadView，查询操作沿着undo log链表从最新版本向老版本遍历**

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master8485522-d5afd5fcad183f18.png)

- **绿色范围可以访问（delete_flag也不应为true，否则这个版本是已经被删除的）**
- **浅绿色范围只能访问自己修改的未commit版本**
- **蓝色范围不允许访问**

**总结只有当前事务修改的未commit版本和所有已提交事务版本允许被访问**

**注意UPDATE操作是基于当前读的值进行修改，而不是视图**

## 三大日志

- bin log：逻辑日志
- redo log：物理日志
- undo log：逻辑日志

### bin log

**binlog用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。**

**binlog是mysql的逻辑日志，并且由Server层进行记录**，使用任何存储引擎的mysql数据库都会记录binlog日志。

- 逻辑日志：可以简单理解为记录的就是sql语句。
- 物理日志：因为mysql数据最终是保存在数据页中的，物理日志记录的就是数据页变更，即数据最终的+1-1的原始逻辑（不包含向where那样定位用的逻辑）。

binlog是通过追加的方式进行写入的，可以通过max_binlog_size参数设置每个binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。

**应用场景：**

- 主从复制：在Master端开启binlog，然后将binlog发送到各个Slave端，Slave端重放binlog从而达到主从数据一致。
- 数据恢复：通过使用mysqlbinlog工具来恢复数据。

### redo log

redo log包括两部分：

- 内存中的日志缓冲(redo log buffer)
- 磁盘上的日志文件(redo log file)。

**WAL(Write-Ahead Logging) 技术：**

**mysql每执行一条DML语句，先将记录写入`redo log buffer`，后续某个时间点再一次性将多个操作记录写到`redo log file`。**

**redo log实际上记录数据页的变更，即物理日志**，实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志:

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterv2-6db2466f157a91021b28f70adbe79791_r.jpg)



### undo log

undo log也是MVCC(多版本并发控制)实现的关键

**undo log是逻辑日志，一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态。**

MVCC的版本链就是在undo log上

## 两阶段提交

假设执行一条SQL语句：

1. 写入redo log，处于prepare状态
2. 写bin log
3. 修改redo log，状态为commit

**原因：**

- 先写redo log后写bin log，若中间系统崩溃，事务有效，数据写入正常，但基于bin log做数据恢复和主从复制缺少该事务，数据不一致
- 先写bin log 后写redo log，若中间系统崩溃，该事务无效，但基于bin log做数据恢复和主从复制会多出该事务，数据不一致

**崩溃恢复：**

- redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；

- 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：

  - 是，则提交事务；

  - 否，回滚事务。

    由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。

## 如何保证事务四大特性

- **原子性**

  undo log，使得事务可以rollback

- **持久性**

  redo log，数据写入时先记录在redo log(物理日志)，在刷入磁盘

- **隔离性**

  读写锁+MVCC

  - **读未提交：**不加锁，会产生脏数据
  - **读已提交：**读不加锁，写数据加写锁，MVCC会在事务每次查询时生成Read View，不会产生间隙锁，会出现不可重复读
  - **可重复读：**读不加锁，写数据加写锁，MVCC仅在事务第一次查询时生成Read View，会产生间隙锁
    - 可重复读隔离级别下如何解决幻读：
      - 快照读：MVCC版本链解决幻读
      - 当前读（增删改都是当前读）：间隙锁
  - **串行化：** 读加读锁，写加写锁，事务串行执行

- **一致性**

  通过原子性、持久性、隔离性

## 悲观/乐观锁

**悲观锁：**

顾名思义，就是对于数据的处理持悲观态度，总认为会发生并发冲突，获取和修改数据时，别人会修改数据。所以在整个数据处理过程中，需要将数据锁定。

悲观锁的实现，通常依靠数据库提供的锁机制实现，比如mysql的排他锁，select .... for update来实现悲观锁。

**乐观锁：**

顾名思义，就是对数据的处理持乐观态度，乐观的认为数据一般情况下不会发生冲突，只有提交数据更新时，才会对数据是否冲突进行检测。

如果发现冲突了，则返回错误信息给用户，让用户自已决定如何操作。

乐观锁的实现不依靠数据库提供的锁机制，需要我们自已实现，实现方式一般是记录数据版本，一种是通过版本号，一种是通过时间戳。

给表加一个版本号或时间戳的字段，读取数据时，将版本号一同读出，数据更新时，将版本号加1。

当我们提交数据更新时，判断当前的版本号与第一次读取出来的版本号是否相等。如果相等，则予以更新，否则认为数据过期，拒绝更新，让用户重新操作。



**乐观锁是基于程序实现的，所以不存在死锁的情况，适用于读多的应用场景。如果经常发生冲突，上层应用不断的让用户进行重新操作，这反而降低了性能，这种情况下悲观锁就比较适用。**

## 数据库三大泛式

- 第一范式（1 NF）：字段不可再拆分。
- 第二范式（2 NF）：表中任意一个主键或任意一组联合主键，可以确定除该主键外的所有的非主键值。
- 第三范式（3 NF）：消除传递依赖，在任一主键都可以确定所有非主键字段值的情况下，不能存在某非主键字段 A 可以获取 某非主键字段 B。



## 复杂SQL语句



- `inner join` 查交集数据

  ```mysql
  SELECT 
  	emp.name, 
  	emp.gender, 
  	dept.dname 
  FROM 
  	emp 
  	INNER JOIN dept ON emp.dep_id = dept.did;
  ```

- `outer join`

  - `left outer join`：查A表所有数据和AB交集部分数据，左表数据一定有，右表数据可以为null
  - `right outer join`：查B表所有数据和AB表交集部分数据，右表数据一定有，左表数据可以为null

- **自连接：**自己连接自己，相当于对两张一样的表进行查询，但必须起别名

- **联合查询：**

  - `union all` 直接合并所有数据

  - `union` 会将数据去重后合并

    ```mysql
    -- 将薪资低于5000的员工,和年龄大于50岁的员工全部查询出来
    SELECT * FROM emp WHERE salary < 5000
    UNION ALL -- 添加ALL将不合并重复记录
    SELECT * FROM emp WHERE age > 50;
    ```

# 【操作系统】

## 同步、异步、阻塞、非阻塞

**同步：**当一个同步调用发出后，调用者要一直等待返回结果。通知后，才能进行后续的执行。

**异步：**当一个异步过程调用发出后，调用者不能立刻得到返回结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。

**阻塞：**是指调用结果返回前，当前线程会被挂起，即阻塞。

**非阻塞：**是指即使调用结果没返回，也不会阻塞当前线程。

## 线程和进程

**进程：**进程是操作系统进行资源分配和调度的基本单位；计算机中一个程序就是一个进程，程序的生命周期就是进程的生命周期

**线程：**线程是进程的一个执行单元，也是进程内部的调度实体，是比进程更小的能独立运行的基本单位；也被称为轻量级进程，一个进程

**区别：**

- 进程是资源分配的最小单位，线程是CPU调度的最小单位；一个进程在其执行的过程中可以产生多个线程
- 创建进程和撤销进程，系统都要为之分配或回收资源，开销远大于创建或撤销线程时的开销
- 不同进程地址空间相互独立，同一进程内的线程共享同一地址空间；进程只能看到自己的线程
- 进程间相互独立，不会相互影响，同一进程中的不同线程可能相互影响，一个线程挂掉可能导致整个进程挂掉

## 为什么需要线程

进程可以使多个程序并发执行，以提高资源的利用率和系统的吞吐量，但是其带来了一些缺点：

- 进程在同一时间只能干一件事情
- 进程在执行的过程中如果阻塞，整个进程就会被挂起，即使进程中有些工作不依赖当前等待的资源，仍然不会执行

基于以上的缺点，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时间和空间开销，提高并发性能

## 进程状态转换

![进程状态图转换图](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterstate-transition-of-process.png)

**创建状态(new)** ：进程正在被创建，尚未到就绪状态。

**就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。

**运行状态(running)** ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。

**阻塞状态(waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。

**结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。



# 【计网】

## OSI七层模型

- **物理层：**
  - 解决两个硬件之间怎么通信的问题，主要作用是传输比特流；
  - 数据称为比特
- **数据链路层：**
  - 通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路
  - 数据称为帧
- **网络层：**
  - 通过路由选择算法，为报文（该层的数据单位，由上一层数据打包而来）通过通信子网选择最适当的路径
  - 这一层定义的是IP地址，通过IP地址寻址，所以产生了IP协议
  - 数据称为IP报文
- **传输层：**
  - 监控数据传输服务的质量（丢包重传），保证报文的正确传输
- **会话层：**
  - 虽然已经可以实现给正确的计算机，发送正确的封装过后的信息了。但我们总不可能每次都要调用传输层协议去打包，然后再调用IP协议去找路由，所以我们要建立一个自动收发包，自动寻址的功能。于是会话层出现了：它的作用就是建立和管理应用程序之间的通信。
- **表示层：**
  - 表示层负责数据格式的转换，将应用处理的信息转换为适合网络传输的格式，或者将来自下一层的数据转换为上层能处理的格式。
- **应用层：**
  - 应用层是计算机用户，以及各种应用程序和网络之间的接口，其功能是直接向用户提供服务，完成用户希望在网络上完成的各种工作

## TCP五层模型

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20210920130513026.png)

### 物理层

> **物理层确保原始的数据可在各种物理媒体上传输**

物理连接两台计算机，在计算机之间通过高低电频传送0，1电信号（比特流）

### 数据链路层

> **数据链路层在不可靠的物理介质上提供可靠的传输**
>
> 基本数据单位称为帧

- **以太网协议：**

  数据链路层采用以太网协议，数据包称为帧，由表头(Head)和数据(Data)两部分组成组成。

  帧大小一般为64-1518字节，较大数据会分成多个帧传送。

  表头大小固定18字节，发送者(SMAC)、接受者(DMAC)和帧大小等数据

- **MAC地址：** 设备物理寻址，连入网络的设备都会有网卡接口，每个网卡有一个唯一地址，这个地址就叫做 MAC 地址

  MAC地址 由 48 个二进制位所构成，在网卡生产时就被唯一标识了

- **广播与ARP协议：**

  在同一个**子网**中，计算机 A 要向计算机 B 发送一个数据包，这个数据包会包含接收者的 MAC 地址。

  当发送时，计算机 A 是通过**广播**的方式发送的，这时同一个子网中的计算机 C, D 也会收到这个数据包的，然后收到这个数据包的计算机，会把数据包的 MAC 地址取出来，与自身的 MAC 地址对比，如果两者相同，则接受这个数据包，否则就丢弃这个数据包。

  **ARP协议：** 地址解析协议，ARP（Address Resolution Protocol），是根据IP地址获取物理地址的一个TCP/IP协议

### 网络层 

> **网络层负责对子网间的数据包进行路由选择，建立设备到设备的通信**
>
> 基本数据单位为IP数据报

- **IP协议：** IP地址用于网络寻址

  IP 地址由 32 位的二进制数组成，一般用点分十进制表示，地址范围为0.0.0.0~255.255.255.255

  IP地址的二进制位数被划分为两部分（不固定），高位为网络部分，低位为主机部分；相同网络部分称为处于同一子网中

  **子网掩码**用以划分IP地址，其高位（网络部分）全为1，低位（主机部分）全为0，IP地址与子网掩码做与运算的结果即为网络部分

  > 192.168.43.1和192.168.43.2
  >
  > 子码掩码都为255.255.255.0
  >
  > 把IP与子码掩码做AND运算，可以得到他们都为192.168.43.0，进而他们处于同一个子网中

- **ARP协议：** 同一子网的两台设备，当广播到达子网后，通过ARP协议得到具体设备的MAC地址

  主机发送信息时，将包含目标IP地址的ARP请求**广播**到局域网络上的所有主机，并接收返回消息，以此确定目标的物理地址；

  收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。

  **当主机A和主机B不在同一网段时，数据包会交给网关处理**

  1. 主机A就会先向**网关**发出ARP请求，ARP请求报文中的目标IP地址为网关的IP地址。

  2. 网关处理数据包，返回主机A它需要的报文

     - 如果网关没有主机B的ARP表项，网关会广播ARP请求，目标IP地址为主机B的IP地址，当网关从收到的响应报文中获得主机B的MAC地址后，就可以将报文发给主机B；

     - 如果网关已经有主机B的ARP表项，网关直接把报文发给主机B。

- **路由选择：** 网络层通过相应的控制算法给出分组数据转发的最优路径

### 传输层

> **建立端口到端口的通信**
>
> 基本数据单位为TCP报文、UDP报文

- TCP协议：可靠传输
- UDP协议：不可靠传输

### 应用层

> 为操作系统或网络应用程序提供访问网络服务的接口
>
> 基本数据单位为各种协议的报文

- 数据传输基本单位为报文；
- 包含的主要协议：
  - FTP（文件传送协议）
  - Telnet（远程登录协议）
  - DNS（域名解析协议）
  - SMTP（邮件传送协议）
  - POP3协议（邮局协议）
  - HTTP协议（Hyper Text Transfer Protocol）

## TCP

**主要特点：**

1. TCP是面向连接的运输层协议；

   所谓面向连接就是双方传输数据之前，必须先建立一条通道，例如三次握手就是建议通道的一个过程，而四次挥手则是结束销毁通道的一个其中过程。

2. TCP连接点对点的

3. TCP提供可靠的传输服务。

   传送的数据无差错、不丢失、不重复、按序到达；

4. TCP提供全双工通信。

   允许通信双方的应用进程在任何时候都可以发送数据，因为两端都设有发送缓存和接受缓存；

5. 面向字节流。

   虽然应用程序与TCP交互是一次一个大小不等的数据块，但TCP把这些数据看成一连串无结构的字节流，它不保证接收方收到的数据块和发送方发送的数据块具有对应大小关系，例如，发送方应用程序交给发送方的TCP10个数据块，但就受访的TCP可能只用了4个数据块就把收到的字节流交付给上层的应用程序，但字节流完全一样。

**可靠性原理：**

可靠传输有如下两个特点:

- 传输信道无差错,保证传输数据正确;
- 不管发送方以多快的速度发送数据,接收方总是来得及处理收到的数据;

1. 首先，采用三次握手来建立TCP连接，四次挥手来释放TCP连接，从而保证建立的传输信道是可靠的。
2. 其次，TCP采用了连续ARQ协议（回退N，Go-back-N；超时自动重传）来保证数据传输的正确性，使用滑动窗口协议来保证接方能够及时处理所接收到的数据，进行流量控制。
3. 最后，TCP使用慢开始、拥塞避免、快重传和快恢复来进行拥塞控制，避免网络拥塞。

## UDP

（１）UDP是无连接的传输层协议；

（２）UDP使用尽最大努力交付，不保证可靠交付；

（３）UDP是面向报文的，对应用层交下来的报文，不合并，不拆分，保留原报文的边界；

（４）UDP没有拥塞控制，因此即使网络出现拥塞也不会降低发送速率；

（５）UDP支持一对一　一对多　多对多的交互通信；

（６）UDP的首部开销小，只有８字节

## TCP和UDP的区别

(1)TCP是可靠传输,UDP是不可靠传输;

(2)TCP面向连接,UDP无连接;

(3)TCP传输数据有序,UDP不保证数据的有序性;

(4)TCP不保存数据边界,UDP保留数据边界;

(5)TCP传输速度相对UDP较慢;

(6)TCP有流量控制和拥塞控制,UDP没有;

(７)TCP是重量级协议,UDP是轻量级协议;

(８)TCP首部较长２０字节,UDP首部较短８字节;

## TCP三次握手

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterv2-2a54823bd63e16674874aa46a67c6c72_r.jpg)

**seq:自己的数据包序号，ack：希望接受到的对方的数据包序号**

**刚开始客户端处于closed状态，服务端处于listen状态：**

1. **第一次握手：**客户端->服务端

   客户端给服务端发送SYN报文，初始化客户端ISN=x，置报文：seq=x

   **客户端处于SYN_SEND状态**

   

2. **第二次握手：**服务端->客户端

   服务端收到客户端的 SYN 报文后会以自己的SYN+ACK报文作为应答，初始化服务端ISN=y，置报文：seq=y, ack=x+1

   **服务端确认：客户端发送正常，服务端接收正常**

   **服务端处于SYN_RCVD状态**

   

3. **第三次握手：**客户端->服务端

​		客户端收到服务端的SYN+ACK报文后，

​		**客户端确认：客户端发送正常，客户端接收正常；服务端接收正常，服务端接收正常**

​		**客户端进入established状态，此时客户端已经可以发送数据**

​		客户端回复服务端ACK报文，置报文：seq=x+1,ack=y+1

​		服务端接收到服务端的ACK报文，

​		**服务端确认： 客户端接收正常，服务端发送正常**

​		**服务端进入established状态**

## 三次握手的作用

1、确认双方的接受能力、发送能力是否正常。

2、指定自己的初始化序列号，为后面的可靠传送做准备。

## 为什么三次握手

TCP协议要建立可靠的连接，就需要保证，对于接收方与发送方双方，都需要确认四点：我方发送正常，我方接收正常；对方发送正常，对方接收正常

1. 第一次握手，接收方确认：对方发送正常，我方接收正常
2. 第二次握手，发送方确认：对方发送正常，对方接收正常；我方发送正常，我方接收正常。发送方进入established状态（这也是为什么第三次握手时发送方可以携带数据）
3. 第三次握手，接收方确认：对方接收正常，我方发送正常，也进入established

## TCP四次挥手

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterv2-92888df73d4608c0a1970c5032612c48_r.jpg)

**刚开始双方都处于established状态，假设客户端先发起关闭请求：**

1. **第一次挥手**

   客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。

   

2. **第二次挥手**

   服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。

   客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态

   

3. **第三次挥手**

   等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态；

   

4. **第四次挥手**

   客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态；

   服务器收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。

   客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

## 为什么要四次挥手

**TCP是全双工通信，既可以发送数据也可以接收数据，所以关闭连接，双方都需要确认，己方不需要发送和接收，对方不需要发送和接收**

- 客户端发送自己的FIN，确认并告知服务端自己不再发送
- 客户端接收服务端的ACK，确认服务端不再接收
- 第二次挥手和第三次挥手中间，是服务端处理和接收数据的时间
- 服务端发送自己的FIN，确认并告知客户端自己不再发送
- 服务端接收客户端的ACK，确认客户端不再接收

**但是三次挥手是可行的，服务端的ACK和FIN可以打包一起发送**

## TCP流量控制

**为什么要流量控制：**

双方在通信的时候，收发双方速率应当步调一致。

如果发送方的发送速率太快，会导致接收方处理不过来，这时候接收方只能把处理不过来的数据存在缓存区里，会**缓存溢出**

**滑动窗口：**

- 接收方每次收到数据包，可以在发送确定报文的时候，同时告诉发送方自己的缓存区还剩余多少是空闲的，我们也把缓存区的剩余大小称之为**接收窗口**大小，用变量来表示接收窗口的大小
- 发送方收到之后，便会调整自己的发送速率，也就是调整自己**发送窗口**的大小，当发送方收到接收窗口的大小为0时，发送方就会停止发送数据，防止出现大量丢包情况的发生

## TCP拥塞控制

# 【Redis】

## Redis线程模型

### Redis为什么是单线程

Redis网络事件处理器是基于文件事件分派器实现的，这个文件事件处理器是单线程的，所以Redis是单线程的

### 文件事件

![640](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master640.png)

### 构成组件

- 多个socket
- I/O多路复用程序
- 文件事件分派器
- 命令请求处理器
- 命令回复处理器
- 连接应答处理器
- 时间处理器(做定时用)

### I/O多路复用的实现

![640 (1)](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master640%20(1).png)

### 文件事件处理器

- 连接应答处理器

  当Redis初始化时，程序会将连接应答处理器与服务端监听套接字的AE_READABLE事件关联起来，当有客户端通过socket连接服务端时，套接字就会产生AE_READABLE事件，引发连接应答处理器执行，并执行相应的套接字应答操作。

- 命令请求处理器

  当一个客户端通第一步通过socket与服务端连接成功后，服务端将会把该socket的AE_READABLE事件和命令请求处理器关联起来，当客户端向服务端发起命令请求时，如 get xxx，set xxx,套接字就会产生AE_READABLE事件，关联的命令请求处理器就会被执行

- 命令回复处理器

  当服务端需要给客户端响应时，服务端会将客户端套接字的AE_WRITABLE事件和命令回复处理器关联，当客户端准备好接受响应数据时，就会触发AE_WRITABLE事件，执行关联的命令回复处理器的程序，执行对应的套接字写入操作，当数据写入完毕，就会将客户端套接字的AE_WRITABLE事件和命令回复处理器解绑，但是客户端套接字的AE_READABLE事件还是会和命令请求处理器关联。

### 完整的客户端与服务端交互流程

![640 (2)](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-master640%20(2).png)

**客户端与Redis通信的一次流程：**

server初始化后，在server_socket上注册`AE_READABLE`事件，并与连接应答处理器关联。

1. 客户端请求与服务端建立连接：server收到`AE_READABLE`事件，通过文件事件分派器，找到关联的连接应答处理器，执行应答程序，并且在客户端的socket上注册`AE_READABLE事件`，并与命令请求处理器关联。
   - 通过文件事件分派器，找到连接应答处理器
   - 在客户端的socket上注册`AE_READABLE`事件，并将事件关联命令请求处理器
2. 客户端发起命令请求：如`set a 1`, server会收到`AE_READABLE`事件，通过文件事件分派器，找到关联的命令请求处理器，在内存中执行命令(命令请求处理器从socket中读出key和value，在内存中完成key和value的设置)，并在客户端的socket上注册`AE_WRITABLE`事件，并与命令回复处理器绑定。
   - 通过文件事件分派器，找到命令请求处理器
   - 在内存中执行命令
   - 在客户端的socket上注册`AE_WRITEABLE`事件，并将事件关联请求回复处理器
3. 客户端告诉server自己准备好接受响应数据了：server会收到`AE_WRITABLE`事件，通过文件事件分派器，找到关联的命令回复处理器，将数据写入socket，写入完毕，再将`AE_WRITABLE`与命令回复处理器解绑。
   - 通过文件事件分派器，找到命令回复处理器
   - 将数据写入socket
   - 将`AE_WRITABLE`事件与命令回复处理器解绑

## 为什么Redis单线程且并发响应效率这么快

- 非阻塞I/O多路复用模型，只有调用select、poll、epoll等函数时才会阻塞，收发客户消息不会阻塞，可以充分利用整个线程
- 纯内存操作
- 单线程模式（因为文件事件分派器是单线程的），避免了不必要的上下文切换及竞争条件；也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
- 数据结构简单，对数据操作也简单，不需要像关系型数据库一样维护复杂的数据结构

## Redis数据类型以及使用场景

- `string`：

  基本数据类型，普通kv操作，

  - 使用场景有很多，比如以userId为`key`，验证码为`value`，设置过期时间做一个验证码功能

- `hash`：

  类似map的一种结构`<hash,key,value>`，一个`hash`对应了一个`<key,value>`的`map`集合；

  - 电商支付项目中，我使用这个数据结构来存放购物车信息，就以userId为`hash`，商品id为`key`，购物车商品对象的json字符串为`value`写入Redis；

    查询购物车的时候就以userId为`hash`查出所有的`<key,value>`键值对，拿到购物车里的所有商品信息

- `list`：

  有序列表，可以按照插入顺序排序，添加元素到列表头部或尾部

  - 在论坛项目中，我使用一个用户的userId为`key`，他粉丝们的userId为`value`，实现了一个粉丝功能
  - Redis 的 lpush + brpop 命令组合即可实现阻塞队列，生产者客户端是用 lpush 从列表左侧插入元素，多个消费者客户端使用 brpop 命令阻塞式的“抢”列表尾部的元素，多个客户端保证了消费的负载均衡和高可用性。

- `set:`

  无序集合，自动去重

  - 一个用户对娱乐、体育比较感兴趣，另一个可能对新闻感兴趣，这些兴趣就是标签，有了这些数据就可以得到同一标签的人，以及用户的共同爱好的标签，这些数据对于用户体验以及曾强用户粘度比较重要

- `sorted set`

  去重且可以排序，写进去的时候给一个分数，他就会根据分数排序

  - 论坛项目中，文章根据热度推送功能就是使用这个数据结构实现的，每天定时更新set集合中热度最高的前10篇文章，实现文章在首页的推送；然后文章每次产生点击时，都会对热度+1

## Redis持久化

持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。Redis 提供了两种持久化方式：RDB（默认）和 AOF。

**RDB**

RDB 是 Redis DataBase 的缩写。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即 Snapshot 快照存储，对应产生的数据文件为 dump.rdb，通过配置文件中的 save 参数来定义快照的周期。核心函数：rdbSave（生成 RDB 文件）和 rdbLoad（从文件加载内存）两个函数。

**AOF**

AOF 是 Append-only file 的缩写。Redis会将每一个收到的写命令都通过 Write 函数追加到文件最后，类似于 MySQL 的 binlog。当 Redis 重启是会通过**重新执行文件中保存的写命令**来在内存中重建整个数据库的内容。每当执行服务器（定时）任务或者函数时，flushAppendOnlyFile 函数都会被调用， 这个函数执行以下两个工作：

- WRITE：根据条件，将 aof_buf 中的缓存写入到 AOF 文件；
- SAVE：根据条件，调用 fsync 或 fdatasync 函数，将 AOF 文件保存到磁盘中。

**RDB 和 AOF 的区别：**

![image-20230413090522037](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230413090522037.png)

- **RDB的优点：**
  - 体积更小：相同的数据量rdb数据比aof的小，因为rdb是紧凑型文件
  - 恢复更快：因为rdb是数据的快照，基本上就是数据的复制，不用重新读取再写入内存
  - 性能更高：父进程在保存rdb时候只需要fork一个子进程，无需父进程的进行其他io操作，也保证了服务器的性能。
- **AOF优点：**
  - 数据保证：我们可以设置fsync策略，一般默认是everysec，也可以设置每次写入追加，所以即使服务死掉了，咱们也最多丢失一秒数据

## 分布式锁

**1、加锁**

使用setnx来加锁。key是锁的唯一标识，按业务来决定命名，value这里设置为test。

```java
setx key test
```

当一个线程执行setnx返回1，说明key原本不存在，该线程成功得到了锁；当一个线程执行setnx返回0，说明key已经存在，该线程抢锁失败；

**2、解锁**

有加锁就得有解锁。当得到的锁的线程执行完任务，需要释放锁，以便其他线程可以进入。释放锁的最简单方式就是执行del指令。

```java
del key
```

释放锁之后，其他线程就可以继续执行setnx命令来获得锁。

**3、锁超时**

锁超时知道的是：如果一个得到锁的线程在执行任务的过程中挂掉，来不及显式地释放锁，这块资源将会永远被锁住，别的线程北向进来。

所以，setnx的key必须设置一个超时时间，以保证即使没有被显式释放，这把锁也要在一段时间后自动释放。setnx不支持超时参数，所以需要额外指令

```*java
expire key 30
```

****

通过上述setnx 、del和expire实现的分布式锁还是存在着一些问题。

**1、SETNX 和 EXPIRE 非原子性**

假设一个场景中，某一个线程刚执行setnx，成功得到了锁。此时setnx刚执行成功，还未来得及执行expire命令，节点就挂掉了。此时这把锁就没有设置过期时间，别的线程就再也无法获得该锁。

**解决措施:**

由于setnx指令本身是不支持传入超时时间的，而在Redis2.6.12版本上为set指令增加了可选参数, 用法如下：

```java
SET key value [EX seconds][PX milliseconds] [NX|XX]
```

- EX second: 设置键的过期时间为second秒；
- PX millisecond：设置键的过期时间为millisecond毫秒；
- NX：只在键不存在时，才对键进行设置操作；
- XX：只在键已经存在时，才对键进行设置操作；
- SET操作完成时，返回OK，否则返回nil。

**2、锁误解除**

如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 实际释放的线程 B 加的锁。

**解决办法：**

在del释放锁之前加一个判断，验证当前的锁是不是自己加的锁。

具体在加锁的时候把当前线程的id当做value，可生成一个 UUID 标识当前线程，在删除之前验证key对应的value是不是自己线程的id。

还可以使用 lua 脚本做验证标识和解锁操作。

**3、超时解锁导致并发**

如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。

A、B 两个线程发生并发显然是不被允许的，一般有两种方式解决该问题：

- 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。
- 为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间。

**4、不可重入**

当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。

**5、无法等待锁释放**

上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。

- 可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获取锁，直到成功获取锁或等待超时。这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。
- 另一种方式是使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。
  具体实现参考

## Redis实现消息队列

通过Redis使用List作为队列，RPUSH生产消息,LPOP消费消息

- 没有等待队列里有值就直接消费

  - `BLPOP testlist 30` 阻塞直到队列有消息或者超时

- 只能供一个消费者消费

  - `pup/sub`：主体订阅者模式，pub发送消息，订阅者sub接收消息

    订阅者可以订阅任意数量的频道，即可实现多消费者消费同一个队列的消息

    **缺点：** 消息发布无状态，无法保证可达（发送消息时消费者宕机，重新上线无法接收到消息），解决此问题必须使用专业的消息队列如kafka

## Redis过期策略

我们都知道，Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。

Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。

过期策略通常有以下三种：

- **定时过期：**

  每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。

  该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。

- **惰性过期：**

  只有当访问一个key时，才会判断该key是否已过期，过期则清除。

  该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。

- **定期清除：**

  每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。
  (expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)

Redis中同时使用了惰性过期和定期过期两种过期策略。

## Redis内存淘汰

定期删除漏掉很多过期key，且这些key不再被访问无法惰性删除，会在内存中堆积过多的key，就需要走内存淘汰机制

内存淘汰策略：

- noeviction：内存不足写入新数据时，新写入操作会报错
- allkeys-lru：内存不足写入新数据时，移除最近最少使用的key
- allekys-random：内存不足写入新数据时，随机删除一个key
- volatile-lru：内存不足写入新数据时，在设置了过期时间的键空间中，移除最近最少使用的key
- volatile-random：内存不足写入新数据时，在设置了过期时间的键空间中，随机删除一个key
- volatile-ttl：当内存不足写入新数据时，在设置了过期时间的键空间里，优先删除最早过期时间的key 

## Redis并发竞争问题

用分布式锁确保同一时间只能有一个系统实例在操作key，别人不允许读和写；且每次要写之前要判断一下当前value的时间戳是否比缓存里的时间戳更新，如果更新就可以写，否则不能用旧的数据覆盖新的数据

![image-20230413101630561](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230413101630561.png)

## 缓存雪崩

**缓存雪崩：** 缓存失效，请求全部走数据库

- Redis挂了

  - 事发前：实现Redis的高可用(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。
  - 事发中：万一Redis真的挂了，我们可以设置本地缓存(ehcache)+限流(hystrix)，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)
  - 事发后：redis持久化，重启后自动从磁盘上加载数据，快速恢复缓存数据。

- 对缓存数据设置相同的过期时间，导致某段时间内缓存失效

  解决方法：给过期时间+一个随机值，减少缓存在同一时间过期

## 缓存穿透

缓存穿透是指查询一个一定**不存在的数据**。由于缓存不命中，并且出于容错考虑，如果从**数据库查不到数据则不写入缓存**，这将导致这个不存在的数据**每次请求都要到数据库去查询**，失去了缓存的意义

**缓存穿透：请求的数据在缓存大量不命中，导致请求走数据库。**

**解决方案：**

- **校验参数合法性**： 由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter提前拦截，不合法就不让这个请求到数据库层！

  布隆过滤器：二进制数组（0，1表示是否存在数据）

- 当我们从数据库找不到的时候，我们也将这个**空对象设置到缓存里边去**。下次再请求的时候，就可以从缓存里边获取了

## 缓存与数据库双写一致

**不一致：数据库的数据跟缓存的数据不一致**

**操作缓存的方案：**

- 更新缓存

- 删除缓存

  一般采用删除缓存策略：

  1. 高并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就**更加容易**导致数据库与缓存数据不一致问题。(删除缓存**直接和简单**很多)
  2. 如果每次更新了数据库，都要更新缓存【这里指的是频繁更新的场景，这会耗费一定的性能】，倒不如直接删除掉。等再次读取时，缓存里没有，那我到数据库找，在数据库找到再写到缓存里边(体现**懒加载**)



数据库与缓存操控的先后顺序：考虑原子性和高并发场景

### 先更新数据库，再删除缓存

正常的情况是这样的：

- 先操作数据库，成功；
- 再删除缓存，也成功；

如果原子性被破坏了：

- 第一步成功(操作数据库)，第二步失败(删除缓存)，会导致**数据库里是新数据，而缓存里是旧数据**。
- 如果第一步(操作数据库)就失败了，我们可以直接返回错误(Exception)，不会出现数据不一致。

如果在高并发的场景下，出现数据库与缓存数据不一致的**概率特别低**，也不是没有：

- 缓存**刚好**失效
- 线程A查询数据库，得一个旧值
- 线程B将新值写入数据库
- 线程B尝试删除缓存，发现没有缓存
- 线程A将查到的旧值写入缓存

> 因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，**而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存**，所有的这些条件都具备的**概率基本并不大**。

### 先删除缓存，再更新数据库

正常情况是这样的：

- 先删除缓存，成功；
- 再更新数据库，也成功；

如果原子性被破坏了：

- 第一步成功(删除缓存)，第二步失败(更新数据库)，数据库和缓存的数据还是一致的。
- 如果第一步(删除缓存)就失败了，我们可以直接返回错误(Exception)，数据库和缓存的数据还是一致的。

看起来是很美好，但是我们在并发场景下分析一下，就知道还是有问题的了：线程A删除缓存-A更新数据的中间，B进行了查询和写缓存

- 线程A删除了缓存
- 线程B查询，发现缓存已不存在
- 线程B去数据库查询得到旧值
- 线程B将旧值写入缓存
- 线程A将新值写入数据库

所以也会导致数据库和缓存不一致的问题。

**并发下解决数据库与缓存不一致的思路**：

- 将删除缓存、修改数据库、读取缓存等的操作积压到**队列**里边，实现**串行化**。

### 策略对比

我们可以发现，两种策略各自有优缺点：

- 先删除缓存，再更新数据库

  在高并发下表现不如意，在原子性被破坏时表现优异

- 先更新数据库，再删除缓存(`Cache Aside Pattern`设计模式)

  在高并发下表现优异，在原子性被破坏时表现不如意

## Hash扩容



# 【JVM】

## 垃圾回收

### 垃圾回收算法

- 复制算法

  把存活对象复制到另一块内存区域，清理掉原来的内存区域里的垃圾

  eden区，survivor-from，survivor-to

- 标记清除算法

  根据可达性分析标记垃圾，清理掉未标记的垃圾

- 标记整理算法

  根据可达性分析标记垃圾，清除掉未标记的垃圾，并整理存活对象，去掉内存碎片

![image-20230410191332370](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410191332370.png)

### 三色标记法

**三色标记法将对象的颜色分为了黑、灰、白，三种颜色**

- 黑色：该对象已经被标记过了，且该对象下的属性也全部都被标记过了。（程序所需要的对象）
- 灰色：该对象已经被标记过了，但该对象下的属性没有全被标记完。（GC需要从此对象中去寻找垃圾）
- 白色：该对象没有被标记过。（对象垃圾）

**算法流程：**

- 从我们`main`方法的根对象（JVM中称为`GC Root`）开始沿着他们的对象向下查找，用黑灰白的规则，标记出所有跟`GC Root`相连接的对象
- 扫描一遍结束后，一般需要进行一次短暂的STW(Stop The World)，再次进行扫描，此时因为黑色对象的属性都也已经被标记过了，所以只需找出灰色对象并顺着继续往下标记（且因为大部分的标记工作已经在第一次并发的时候发生了，所以灰色对象数量会很少，标记时间也会短很多）
- 此时程序继续执行，`GC`线程扫描所有的内存，找出被标记为白色的对象（垃圾）清除

**存在问题**

1. 浮动垃圾：并发标记的过程中，若一个已经被标记成黑色或者灰色的对象，突然变成了垃圾，此时，此对象不是白色的不会被清除，重新标记也不能从`GC Root`中去找到，所以成为了浮动垃圾，这种情况对系统的影响不大，留给下一次GC进行处理即可。

2. 对象漏标问题（需要的对象被回收）：

   ![image-20230411085237664](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411085237664.png)

   黑色对象引用了一个未被扫描的白色对象，同时灰色对象断开了对白色对象的引用，此时该白色对象将不再被扫描并标记为存活对象。

   1. 有至少一个黑色对象在自己被标记之后指向了这个白色对象
   2. 所有的灰色对象在自己引用扫描完成之前删除了对白色对象的引用

   **解决方法：**

   - CMS：增量更新，破坏条件1，关注引用的新增

     当一个黑色对象增加了对白色对象的引用，CMS会记录下这个引用，相当于将黑色对象变灰，在最后标记的时候,再以这个黑色对象为根,对它的引用进行重新扫描

   - G1：原始快照，破坏条件2，关注引用的删除

     当一个灰色对象取消了对白色对象的引用，G1会记录下这个引用，相当于将这个白色对象变灰，最后标记的时候，再以这个白色对象为根进行扫描

### 如何判断一个对象是否死亡

- 可达性分析算法：

  GC Roots作为初始的存活对象合集，然后从该合集出发，探索所有能够被该合集引用到的对象，并将其加入到该和集中，这个过程称之为标记。 

  最终，未被探索到的对象便是死亡的，是可以回收的。

- 引用计数法：

  为每个对象添加一个引用计数器，用来统计指向该对象的引用个数。 一旦某个对象的引用计数器为0，则说明该对象已经死亡，便可以被回收了。

### 哪些可以作为GC-ROOT

- 虚拟机栈中，线程内部，栈帧中，局部变量表里的局部变量引用的对象

- 方法区中已加载的类的静态变量

- 方法区中常量引用的对象

- JNI（Java Native Interface）指针引用的对象

### 常见的垃圾回收器

- **Serial/Serial Old：** 单线程回收新生代/老年代的复制算法的垃圾回收器
- **Parallel Scavenge/Old：** jdk1.8版本默认的多线程回收新生代/老年代的垃圾回收器
- **ParNew + CMS：** 新生代+老年代组合的垃圾回收器，尽量减少停顿时间
- **G1**

### CMS垃圾回收器

![image-20230410191848063](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410191848063.png)

- CMS只回收老年代
- CMS关注点是尽可能缩短垃圾回收时用户线程的停顿时间
- CMS垃圾回收期是预处理垃圾回收期，需要有触发阈值，默认久带达到92%（因为无法处理浮动垃圾，需要预留空间）
- 步骤：
  - 初始标记：stw，仅标记gc-root
  - 并发标记：进行可达性分析
  - 重新标记：stw，修正因为程序运行导致标记变动的对象
  - 并发清除：清理死亡对象
- **优点：**
  - 并发
  - 延迟低
- **缺点：**
  - 会产生内存碎片
  - 无法处理浮动垃圾（并发清除时如果老年代满了，会进行FULL GC并造成stw）

### G1垃圾回收器

![image-20230410193144489](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410193144489.png)

- G1垃圾回收器将堆空间分成了很多个Region，每个Region存放一些对象
- 逻辑上保留分代模型，Region可以作为新生代Region只存放新生代对象，可以作为老年代Region只存放老年代对象，还有特殊的预留Humongous区可以存放大对象
- G1跟踪各个Region里面的垃圾堆积的价值大小(回收所获得的空间大小以及回收所需时间的经验值),在后台维护一个优先列表，每次根据允许的收集时间,优先回收价值最大的Region。保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。从而实现一个相对可控的停顿时间
- G1垃圾回收器也是采用标记-清除算法

### 老年代和新生代GC

![img](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterv2-b41981011abd9cd9a00c90588a8ea113_r.jpg)

- Minor GC

  此时会将S0区与Eden区的对象一起进行可达性分析，找出存活的对象，将它复制到S1区，并清空剩下的区域

- Major GC

  发生在老年代的GC

![image-20230410195120244](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410195120244.png)

### 堆空间/分代模型

![image-20230410191425652](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410191425652.png)

新生代：复制算法

老年代：标记清除算法、标记整理算法

## JVM如何加载.class文件

![image-20230410181802264](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410181802264.png)

- **加载**：加载字节码文件到内存
- **校验**：校验.class文件是否符合虚拟机规范
- **准备**：为类分配一定的内存空间，并给里面的类变量（static修饰的变量）分配内存空间和默认的初始值
- **解析**：将符号引用替换为直接引用（在编译的时候一个每个java类都会被编译成一个class文件，但在编译的时候虚拟机并不知道所引用类的地址，所以就用符号引用来代替，而在解析阶段就是为了把这个符号引用转化成真正的地址的阶段）
- **初始化**：执行初始化语句，如静态变量的赋值操作、静态代码的执行；若有父类会先初始化父类

## 双亲委派机制

![image-20230411100010222](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411100010222.png)

![image-20230411095956820](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411095956820.png)

**优点：**

- 通过带有优先级的层级关系可以避免类的重复加载
- 保证Java程序安全稳定运行，Java 核心 API 定义类型不会被随意替换

## JVM运行时数据区

![image-20230411091621486](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411091621486.png)

![Java 运行时数据区域（JDK1.8 之后）](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterjava-runtime-data-areas-jdk1.8.png)

## 对象头

![image-20230411092931188](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411092931188.png)



![image-20230411093204553](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411093204553.png)

对齐填充：对象占用大小应当是8字节的整数倍

## JVM启动参数

```properties
# JVM启动参数不换行

# 设置堆空间最大值最小值
-Xmx4g -Xms4g
# 指定Meta区（方法区）的最大值
-XX:MaxMetaspaceSize=2g

# 指定GC算法，选用G1垃圾回收器，指定停顿时长50ms
-XX:+UseG1GC -XX:MaxGCPauseMillis=50
# 指定GC并行线程数
-XX:ParallelGCThreads=4
# 打印GC日志
-XX:+PrintGCetails -XX:+PrintGCDateStamps
# 指定GC日志文件
-Xloggc:gc.log

```

## 设置堆空间的最大值



## 跨平台/语言无关性

![image-20230410181043737](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410181043737.png)

**跨平台：** java语言编写的.java文件编译成.class文件，然后交给Jvm解析成特定平台的机器指令，从软件层面屏蔽不同操作系统在底层硬件和指令的区别，实现跨平台。

**语言无关性：**同时，Jvm只识别字节码文件，所以其和语言解耦，不仅仅是java语言，其他语言只要能编译成符合jvm规范的字节码文件，就可以在jvm上运行。

## Jvm解释执行/JIT

解释执行：通过程序计数器逐行解析字节码文件成本地机器指令来执行

JIT(及时编译器)：对于热点代码，JIT会把热点代码（频繁调用的代码）直接编译成本地机器指令，不需要再逐行解释执行

## 对象一定在堆中间创建吗

几乎所有的对象都在堆中创建

当代码为热点代码，被JIT即时编译优化，如果判断对象无法逃逸出当前方法，并且JVM开启标量替换，就会在栈上分配

![image-20230410185126393](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230410185126393.png)

## 排查OOM问题

```properties
# 推荐生产环境开启以下参数
# 当OOM发生时自动dump堆内存信息
-XX:+HeapDumpOnOutOfMemoryError 
# dump堆内存信息存放目录
-XX:HeapDumpPath=/tmp/heapdump.hprof
```

使用Visual VM 查看.hprof文件

## JVM相关命令工具

![image-20230411103328200](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411103328200.png)

![image-20230411103345339](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411103345339.png)

![image-20230411103607515](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411103607515.png)

![image-20230411103621439](https://chongming-images.oss-cn-hangzhou.aliyuncs.com/images-masterimage-20230411103621439.png)
